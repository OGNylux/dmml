{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQr8z-ivMXBT"
   },
   "source": [
    "# DMML-Übungseinheit am 07.11.2024 (12:10-14:35) 3 EH<a class=\"jp-toc-ignore\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Aufzeichen einschalten!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVEFeTBLH-4y"
   },
   "source": [
    "# Einzelabgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEV9GOCrIEP7"
   },
   "source": [
    "* Einzelabgabe mit Deadline 26.11. 23:59 ist hochgeladen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gruppenabgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denkt daran, eure Gruppe zusammenzustellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeitplan für heute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>12:10 bis 12:55</b><br>\n",
    "<b>13:00 bis 13:45</b><br>\n",
    "<b>13:50 bis 14:35</b><br>\n",
    "\n",
    "Präsentation Gruppe 9<br>\n",
    "Feedback Abgaben<br>\n",
    "Zusätzliche Aspekte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rückblick Übung (05.11.2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Alle Gruppen haben Notebbook abgegeben\n",
    "<li>Alle TeilnehmerInnen waren durchgehend anwesend\n",
    "<li>In jedem Notebook wurden jeweils nur die beiden angegebenen Teilaufgaben berarbeitet.<br>\n",
    "    Gerade, die früher fertig sind - nutzt die Gelegenheit im Machine Learning Erfahrungen zu sammeln.\n",
    "<li>Qualität war durchwegs gut - eine Gruppe ist bei der Codequalität etwas abgefallen.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries und Datenimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:41:56.248362700Z",
     "start_time": "2024-11-07T11:41:50.977226700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df       = pd.read_csv(\"fish.csv\", encoding=\"utf-8\")\n",
    "df_train = pd.read_csv(\"fish_train.csv\", encoding=\"utf-8\")\n",
    "df_test  = pd.read_csv(\"fish_test.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y       = df.Weight\n",
    "y_train = df_train.Weight\n",
    "y_test  = df_test.Weight\n",
    "\n",
    "X       = df.drop([\"Species\",\"Weight\"], axis=1)\n",
    "X_train = df_train.drop([\"Species\",\"Weight\"], axis=1)\n",
    "X_test  = df_test.drop([\"Species\",\"Weight\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruppe 1 (A1+A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Tipp zu matplotlib: ein\";\" am Ende der letzten Codezeile ersetzt die letzte Codezeile plt.show()\n",
    "<li>Histogram: Höhe zu groß, zu viele Bins (siehe später)\n",
    "<li>Gut: Vergleich Eigenschaften training und test\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORGIINAL\n",
    "# figsize war (15,7) wurde zu (10,10) geändert\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.histplot(data=df, x=\"Weight\", bins=50)\n",
    "plt.title(\"df\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.histplot(data=df_train, x=\"Weight\", bins=50)\n",
    "plt.title(\"df_train\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.histplot(data=df_test, x=\"Weight\", bins=50)\n",
    "plt.title(\"df_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Wie viele bins - welche Breite - ist sinnvoll?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = 20\n",
    "MinWeight = -widths\n",
    "MaxWeight = max(df.Weight)+100\n",
    "MaxCount = 18\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.histplot(data=df, x=\"Weight\", bins=round(max(df.Weight)/widths))\n",
    "plt.title(\"df\")\n",
    "plt.xlim(MinWeight, MaxWeight)\n",
    "plt.ylim(0, MaxCount)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.histplot(data=df_train, x=\"Weight\", bins=round(max(df_train.Weight)/widths))\n",
    "plt.title(\"df_train\")\n",
    "plt.xlim(MinWeight, MaxWeight)\n",
    "plt.ylim(0, MaxCount)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.histplot(data=df_test, x=\"Weight\", bins=round(max(df_test.Weight)/widths))\n",
    "plt.title(\"df_test\");\n",
    "plt.xlim(MinWeight, MaxWeight)\n",
    "plt.ylim(0, MaxCount);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruppe 3 (A4)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Code zum Import der Packages unübersichtlich und mit Redundanzen, bspw. machen beiden Zeilen dasselbe:<br>\n",
    "<b>from matplotlib import pyplot as plt<br>\n",
    "import matplotlib.pyplot as plt </b>\n",
    "<li>\n",
    "Tipp: describe() mit gleichzeitigem Runden: <b>df.describe().round(2)</b>\n",
    "<li>Die erste Codezeile wird von der zweiten überschrieben:<br>\n",
    "<b>reg_model = linear_model.LinearRegression()<br>\n",
    "reg_model = LinearRegression().fit(X_train, y_train)</b>\n",
    "<li>Namenskonvention df: df sollte Target und Features enthalten<br>\n",
    "    df_test2 = df_test.drop([\"Species\",\"Weight\"], axis=1)<br>\n",
    "    <b>Sobald Target gelöscht wird => X verwenden</b>\n",
    "<li> Danach kamen die folgenden Zeilen - das kann nicht klappen, da auf \"model\" und nicht auf \"reg_model\" verwiesen wurde:<br>\n",
    "print(model.intercept_) <br>\n",
    "print(model.feature_names_in_)<br>\n",
    "print(model.coef_)\n",
    "<li> Mit reg_model kommt das folgende heraus:<br>\n",
    "-516.7128473298876<br>\n",
    "['Length1' 'Length2' 'Length3' 'Height' 'Width']<br>\n",
    "[ 67.55940439 -18.22763355 -22.57284496  25.19276393  31.85419489]\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruppe 4 (A5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>die folgenden beiden Codezeilen passen nicht zumsammen, warum???<br>\n",
    "    model = smf.ols(formula, data=df).fit()<br>\n",
    "    y_pred = model.predict(X_train)\n",
    "<li><b>Das ist ein schwerwiegender Fehler, der leicht passieren kann!</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verschiedene Arten Lineare Regression mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels - klassisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test  = sm.add_constant(X_test)\n",
    "model   = sm.OLS(y_train, X_train).fit()\n",
    "# print(model.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels - mit Formel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model = smf.ols('Weight ~ Length1 + Length2 + Length3 + Height + Width', data=df_train).fit()\n",
    "# print(model.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "# pd.concat( [ pd.DataFrame({\"Feature\": ['Intercept'],\"Coefficients\":np.transpose(model.coef_[0])})   ,pd.DataFrame({\"Feature\":X.columns,\"Coefficients\":np.transpose(model.coef_[1:])})]   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nicht-lineare Zusammenhänge Regression - feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Besipiele</b>:<br>\n",
    "<ul>\n",
    "<li>Feature Engineering - Verwendung von $x^2$, $\\sqrt{x}$, $3 e^{2x}$ oder $x_1x_2^2$ als zusätzliche Features\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Length1', y='Weight', hue='Species', data=df)\n",
    "plt.title('Gewicht vs. Länge1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Length1_squared'] = df.Length1**2\n",
    "sns.scatterplot(x='Length1_squared', y='Weight', hue='Species', data=df)\n",
    "plt.title('Gewicht vs. quadrierte Länge1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lm0' in globals(): del lm0\n",
    "lm0 = smf.ols('Weight ~ Length1 + Length2 + Length3 + Height + Width', data=df_train).fit()\n",
    "print(lm0.summary2())\n",
    "y_pred = lm0.predict(X_test)\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lm' in globals(): del lm\n",
    "lm = smf.ols('Weight ~ np.square(Length1) + Length2 + np.square(Height) + np.square(Width)', data=df_train).fit()\n",
    "print(lm.summary2())\n",
    "y_test_pred = lm.predict(X_test)\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12), sharey=False)\n",
    "\n",
    "# ohne Transformation\n",
    "y_train_pred = lm0.predict(X_train)\n",
    "\n",
    "axs[0,0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0,0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0,0].set_xlabel('Predicted Weight')\n",
    "axs[0,0].set_ylabel('Weight')\n",
    "axs[0,0].grid()\n",
    "axs[0,0].set_title('Train: Weight ~ Length1+\\n Length2+Length3+Height+Width')\n",
    "axs[0,0].set_xlim([mins, maxs])\n",
    "axs[0,0].set_ylim([mins, maxs])\n",
    "axs[0,0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# mite Transformation\n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "axs[1,0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[1,0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1,0].set_xlabel('Predicted Weight')\n",
    "axs[1,0].set_ylabel('Weight')\n",
    "axs[1,0].grid()\n",
    "axs[1,0].set_title('Train: Weight ~ np.square(Length1)+\\n Length2+np.square(Height)+np.square(Width)')\n",
    "axs[1,0].set_xlim([mins, maxs])\n",
    "axs[1,0].set_ylim([mins, maxs])\n",
    "axs[1,0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "\n",
    "# ohne Transformation\n",
    "y_test_pred = lm0.predict(X_test)\n",
    "\n",
    "axs[0,1].scatter(y_test_pred, y_test,sizes)\n",
    "axs[0,1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0,1].set_xlabel('Predicted Weight')\n",
    "axs[0,1].set_ylabel('Weight')\n",
    "axs[0,1].grid()\n",
    "axs[0,1].set_title('Test: Weight ~ Length1+\\n Length2+Length3+Height+Width')\n",
    "axs[0,1].set_xlim([mins, maxs])\n",
    "axs[0,1].set_ylim([mins, maxs])\n",
    "axs[0,1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# mit Transformation\n",
    "y_test_pred = lm.predict(X_test)\n",
    "\n",
    "axs[1,1].scatter(y_test_pred, y_test,sizes)\n",
    "axs[1,1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1,1].set_xlabel('Predicted Weight')\n",
    "axs[1,1].set_ylabel('Weight')\n",
    "axs[1,1].grid()\n",
    "axs[1,1].set_title('Test: Weight ~ np.square(Length1)+\\n Length2+np.square(Height)+np.square(Width)')\n",
    "axs[1,1].set_xlim([mins, maxs])\n",
    "axs[1,1].set_ylim([mins, maxs])\n",
    "axs[1,1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Selection and Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection with sklearn.feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/dev/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n",
    "from sklearn.feature_selection import SequentialFeatureSelector \n",
    "lr = LinearRegression() \n",
    "\n",
    "# forward selection\n",
    "for features in range(1,X_train.shape[1]): # 4 cycles ... 5 cycles would not make sense (5 features used)\n",
    "    sfs = SequentialFeatureSelector(lr, n_features_to_select=features, cv=5, scoring='r2', direction='forward') # n_features_to_select ... features per cycle, cv ... cross validation, quality of model ... R^2) \n",
    "    sfs.fit(X_train,y_train)\n",
    "    print(sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection with mlxtend.feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/anupamujawane/feature-selection-beginner-s-guide\n",
    "# pip install mlxtend  \n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(lr, k_features='best', forward=True, floating=False, verbose=0, scoring='r2', cv=5)\n",
    "\n",
    "sfs1 = sfs1.fit(X_train,y_train)\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best feature subset: {sfs1.k_feature_names_}\")\n",
    "print(f\"R2: {sfs1.k_score_.round(3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Weight ~ Length1 + Length3 + Height + Width', data=df).fit()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(model.summary2())\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6), sharey=False)\n",
    "\n",
    "# TRAINIG\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "axs[0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0].set_xlabel('Predicted Weight')\n",
    "axs[0].set_ylabel('Weight')\n",
    "axs[0].grid()\n",
    "axs[0].set_title('Train: Weight ~ Length1 + Length3 + Height + Width')\n",
    "axs[0].set_xlim([mins, maxs])\n",
    "axs[0].set_ylim([mins, maxs])\n",
    "axs[0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# TEST\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "axs[1].scatter(y_test_pred, y_test, sizes)\n",
    "axs[1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1].set_xlabel('Predicted Weight')\n",
    "axs[1].set_ylabel('Weight')\n",
    "axs[1].grid()\n",
    "axs[1].set_title('Test: Weight ~ Length1 + Length3 + Height + Width')\n",
    "axs[1].set_xlim([mins, maxs])\n",
    "axs[1].set_ylim([mins, maxs])\n",
    "axs[1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Elimination with sklearn.feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward selection\n",
    "for features in range(1,X_train.shape[1]): # 4 cycles ... 5 cycles would not make sense (5 features used)\n",
    "    sfs = SequentialFeatureSelector(lr, n_features_to_select=features, cv=5, scoring='r2', direction='backward') # n_features_to_select ... features per cycle, cv ... cross validation, quality of model ... R^2) \n",
    "    sfs.fit(X_train,y_train)\n",
    "    print(sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1 = SFS(lr, k_features='best', forward=False, floating=False, verbose=0, scoring='r2', cv=5)\n",
    "sfs1 = sfs1.fit(X_train,y_train)\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best feature subset: {sfs1.k_feature_names_}\")\n",
    "print(f\"R2: {sfs1.k_score_.round(3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Weight ~ Length1 + Length3 + Height', data=df).fit()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(model.summary2())\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6), sharey=False)\n",
    "\n",
    "# TRAINIG\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "axs[0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0].set_xlabel('Predicted Weight')\n",
    "axs[0].set_ylabel('Weight')\n",
    "axs[0].grid()\n",
    "axs[0].set_title('Train: Weight ~ Length1 + Length3 + Height')\n",
    "axs[0].set_xlim([mins, maxs])\n",
    "axs[0].set_ylim([mins, maxs])\n",
    "axs[0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# TEST\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "axs[1].scatter(y_test_pred, y_test, sizes)\n",
    "axs[1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1].set_xlabel('Predicted Weight')\n",
    "axs[1].set_ylabel('Weight')\n",
    "axs[1].grid()\n",
    "axs[1].set_title('Test: Weight ~ Length1 + Length3 + Height')\n",
    "axs[1].set_xlim([mins, maxs])\n",
    "axs[1].set_ylim([mins, maxs])\n",
    "axs[1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR mit kategoriellen Variablen: Interaktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetzt: Designmatriten mit \"Species\"\n",
    "X       = df.drop([\"Weight\"], axis=1)\n",
    "X_train = df_train.drop([\"Weight\"], axis=1)\n",
    "X_test  = df_test.drop([\"Weight\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fish.csv')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mit der folgenden Schreibweise werden automatisch kategorielle Variable codiert (entsprechend drop_first = True)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Weight ~ Species + Length1 + Height + Width', data=df).fit()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(model.summary2())\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>BREAM (Basisfischtyp für das Interzept):</b><br>\n",
    "$\\text{Weight} = -743 + 38 * \\text{Length1} + 13 * \\text{Height}  + 2 * \\text{Width}$<br>\n",
    "<b>PARKKI:</b><br>\n",
    "$\\text{Weight} = -743 + 63 + 38 * \\text{Length1} + 13 * \\text{Heigh}t  + 2 * \\text{Width}$<br><br>\n",
    "<b>Pro Fischtyp wird nur das Interzept, nicht aber die anderen Parameter angepasst!<br>\n",
    "<b>Hier erfolgt keine \"Interaktion\" zwischen Fischtyp und den anderen Parametern!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6), sharey=False)\n",
    "\n",
    "# TRAINIG\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "axs[0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0].set_xlabel('Predicted Weight')\n",
    "axs[0].set_ylabel('Weight')\n",
    "axs[0].grid()\n",
    "axs[0].set_title('Train: Weight ~ Species+Length1+Height+Width')\n",
    "axs[0].set_xlim([mins, maxs])\n",
    "axs[0].set_ylim([mins, maxs])\n",
    "axs[0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# TEST\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "axs[1].scatter(y_test_pred, y_test, sizes)\n",
    "axs[1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1].set_xlabel('Predicted Weight')\n",
    "axs[1].set_ylabel('Weight')\n",
    "axs[1].grid()\n",
    "axs[1].set_title('Test: Weight ~ Species+Length1+Height+Width')\n",
    "axs[1].set_xlim([mins, maxs])\n",
    "axs[1].set_ylim([mins, maxs])\n",
    "axs[1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Weight ~ Species*Length1 + Species*Length3 + Species*Height + Width ', data=df).fit()\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(model.summary2())\n",
    "print()\n",
    "print(f'R2(Testdaten)= {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>BREAM (Basisfischtyp für das Interzept + Parameter Länge1):</b><br>\n",
    "$\\text{Weight} = -997 + 17 * \\text{Length1} - 3 * \\text{Length3} + 68 * \\text{Height}  + 35 * \\text{Width}$<br><br>\n",
    "<b>PARKKI:</b><br>\n",
    "$\\text{Weight} = -997 + 757 + ( 17 + 135)  * \\text{Length1} + (-3-116) * \\text{Length3} + ( 68 - 50)  * \\text{Height}  + 35 * \\text{Width}$<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6), sharey=False)\n",
    "\n",
    "# TRAINIG\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "axs[0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[0].set_xlabel('Predicted Weight')\n",
    "axs[0].set_ylabel('Weight')\n",
    "axs[0].grid()\n",
    "axs[0].set_title('Train: Weight ~ Species*Length1 \\n + Species*Length3 + Species*Height + Width')\n",
    "axs[0].set_xlim([mins, maxs])\n",
    "axs[0].set_ylim([mins, maxs])\n",
    "axs[0].text(-5, 1750, f'R2(Train)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "\n",
    "# TEST\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "axs[1].scatter(y_test_pred, y_test, sizes)\n",
    "axs[1].plot(linex, line, color='orange', linestyle='-', label='Custom Line');\n",
    "axs[1].set_xlabel('Predicted Weight')\n",
    "axs[1].set_ylabel('Weight')\n",
    "axs[1].grid()\n",
    "axs[1].set_title('Test: Weight ~ Species*Length1 + \\n Species*Length3 + Species*Height + Width')\n",
    "axs[1].set_xlim([mins, maxs])\n",
    "axs[1].set_ylim([mins, maxs])\n",
    "axs[1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Zusammenfassung Interaktion:</b>\n",
    "<ul>\n",
    "<li><b>Interaktionen erzeugen (viele) zusätzliche Features</b>\n",
    "<li><b>Ohne Interaktion gab es 10 (4+6) Parameter - mit jeder Interaktion 6 Parameter zusätzlich</b>\n",
    "<li><b>Sollen einzelne Interaktionsterme (bspw. mit Forward Selection oder Backward Elimination) ausgeuscht werden, sind die entsprechen Spalten vorher der Linearen Regression zu erzeugen:<br> \n",
    "    Length1_Parkki = Length1, falls typ=Parkki, sonst 0.<br>\n",
    "    Length1_Perch  = Length1, falls typ=Perch, sonst 0.<br>\n",
    "    .....</b>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Term <b>\"Species\\*Length1\"</b> ist eine Kurzschreibweise für <b>\"Species + Height + Species\\*Length1\"</b><br><br>\n",
    "Die folgenden beiden Schreibweisen sind daher äquivalent:<br>\n",
    "model = smf.ols('Weight ~ Species + Length1 + Species\\*Length1 ', data=df)<br>\n",
    "model = smf.ols('Weight ~ Species\\*Length1 ', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verschiedene Trainings/Testsplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listen erstellen, in denen die Werte gespeichert werden\n",
    "mse_values = []\n",
    "r2_score_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(100):\n",
    "\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, random_state=x)\n",
    "\n",
    "    # Train- und Test-Features und Zielvariable\n",
    "\n",
    "#    cols = [\"Length1\", \"Length2\", \"Length3\", \"Width\", \"Height\"]  # lm0\n",
    "#    cols = [\"Length1\",            \"Length3\", \"Width\", \"Height\"]  # lm1\n",
    "#    cols = [           \"Length2\", \"Length3\", \"Width\", \"Height\"]  # lm2\n",
    "#    cols = [\"Length1\",                       \"Width\", \"Height\"]  # lm3\n",
    "#    cols = [                                 \"Width\", \"Height\"]  # lm4\n",
    "#    cols = [                                          \"Height\"]  # lm5\n",
    "    cols = [\"Length1\",            \"Length3\",          \"Height\"]  # lm0\n",
    "    \n",
    "    \n",
    "    X_train = train_data[cols]\n",
    "    y_train = train_data[\"Weight\"]\n",
    "    \n",
    "    X_test = test_data[cols] \n",
    "    y_test = test_data[\"Weight\"]\n",
    "\n",
    "    # Hinzufügen eines konstanten Terms\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    X_test  = sm.add_constant(X_test)\n",
    "\n",
    "    # Lineare Regression mit statsmodels\n",
    "    model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "    #print(model.summary())\n",
    "    \n",
    "    # Vorhersage für die Testdaten\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Berechnung MSE und Hinzufügen zur Liste\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "    # Berechnung R^2-Score und Hinzufügen zur Liste\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_score_values.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(min(r2_score_values)*100,1))\n",
    "print(round(sum(r2_score_values)/len(r2_score_values)*100,1))\n",
    "print(round(max(r2_score_values)*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(min(mse_values)))\n",
    "print(int(sum(mse_values)/len(r2_score_values)))\n",
    "print(int(max(mse_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LOO = X[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
    "\n",
    "scores = cross_val_score(model, X_LOO, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'MSE Minumum:    {int(min(absolute(scores)))}')\n",
    "print(f'MSE Mittelwert: {int(mean(absolute(scores)))}')\n",
    "print(f'MSE Maximum:    {int(max(absolute(scores)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LOO = X[['Length1',             'Length3', 'Height', 'Width']]\n",
    "\n",
    "scores = cross_val_score(model, X_LOO, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'MSE Minumum:    {int(min(absolute(scores)))}')\n",
    "print(f'MSE Mittelwert: {int(mean(absolute(scores)))}')\n",
    "print(f'MSE Maximum:    {int(max(absolute(scores)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LOO = X[['Length1',             'Length3', 'Height'           ]]\n",
    "\n",
    "scores = cross_val_score(model, X_LOO, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'MSE Minumum:    {int(min(absolute(scores)))}')\n",
    "print(f'MSE Mittelwert: {int(mean(absolute(scores)))}')\n",
    "print(f'MSE Maximum:    {int(max(absolute(scores)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Algorithmen zur Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.geeksforgeeks.org/regression-in-machine-learning/)<br>\n",
    "Im folgenden sind einige zusätzliche häufig verwendete Algorithmen aufgelistet.<br>\n",
    "Etwas abgewandelte Algorithmen werden auch zur Klassifikation eingesetzt.\n",
    "<ul>\n",
    "<li>Support Vector Regression (SVR)<br>\n",
    "<li>Decision Tree Regression\n",
    "<li>Random Forest Regression\n",
    "<li>Künstliche neuronale Netze\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Algorithmen haben gemeinsam:<br>\n",
    "Es sind immer einige Hyperparameter auszuwählen (Größe der Bäume, Anzahl Layers, etc.)<br>\n",
    "Es ist nicht so einfach festzustellen, welche Features entscheidend waren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Als Beispiel: der Random Forest Regressor</b><br>\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "<br>\n",
    "Achtung: Dieser Algortithmus benötigt numerische Features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd.concat to join the new columns with your original dataframe\n",
    "df_train_enc = pd.concat([df_train,pd.get_dummies(df_train['Species'], prefix='spec',drop_first=True)],axis=1)\n",
    "df_test_enc = pd.concat([df_test,pd.get_dummies(df_test['Species'], prefix='spec',drop_first=True)],axis=1)\n",
    "# now drop the original 'Species' column (you don't need it anymore)\n",
    "df_train_enc.drop(['Species'],axis=1, inplace=True)\n",
    "df_test_enc.drop(['Species'],axis=1, inplace=True)\n",
    "# drop the target\n",
    "X_train_enc = df_train_enc.drop(['Weight'],axis=1)\n",
    "X_test_enc = df_test_enc.drop(['Weight'],axis=1)\n",
    "# cols that are missing in \"test\" missing\n",
    "cols = list(set(X_train_enc.columns) - set(X_test_enc.columns))\n",
    "# add missing cols For col in missingcols:\n",
    "X_test_enc[cols] = 0\n",
    "# ensure that the order of the columns in test is equal to train\n",
    "X_test_enc = X_test_enc.loc[:,X_train_enc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest Regressor erstellen und trainieren\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_enc, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train_enc)\n",
    "y_test_pred  = model.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2(Training)= {round(r2_score(y_train, y_train_pred)*100,1)}%')\n",
    "print(f'R2(Test)    = {round(r2_score(y_test, y_test_pred)*100,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 1\n",
    "intercept = 0\n",
    "mins = -250\n",
    "maxs = 2000\n",
    "sizes = 6\n",
    "linex = pd.Series([-250,2000])\n",
    "line = slope * linex + intercept\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6), sharey=False)\n",
    "\n",
    "# TRAINIG\n",
    "y_train_pred = model.predict(X_train_enc)\n",
    "\n",
    "axs[0].scatter(y_train_pred, y_train,sizes)\n",
    "axs[0].plot(linex, line, color='orange', linestyle='-', label='Custom Line')\n",
    "axs[0].set_xlabel('Predicted Weight')\n",
    "axs[0].set_ylabel('Weight')\n",
    "axs[0].grid()\n",
    "axs[0].set_title('Train: Random Forest Regressor')\n",
    "axs[0].set_xlim([mins, maxs])\n",
    "axs[0].set_ylim([mins, maxs])\n",
    "axs[0].text(-5, 1750, f'R2(Test)= {round(r2_score(y_train, y_train_pred)*100,1)}%', fontsize = 16);\n",
    "# TEST\n",
    "y_test_pred = model.predict(X_test_enc)\n",
    "\n",
    "axs[1].scatter(y_test_pred, y_test, sizes)\n",
    "axs[1].plot(linex, line, color='orange', linestyle='-', label='Custom Line')\n",
    "axs[1].set_xlabel('Predicted Weight')\n",
    "axs[1].set_ylabel('Weight')\n",
    "axs[1].grid()\n",
    "axs[1].set_title('Test: Random Forest Regressor')\n",
    "axs[1].set_xlim([mins, maxs])\n",
    "axs[1].set_ylim([mins, maxs])\n",
    "axs[1].text(-5, 1750, f'R2(Test)= {round(r2_score(y_test, y_test_pred)*100,1)}%', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übersicht der Methoden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ergebnisse bei vorgegebener Aufteilung Training/Test, sortiert nach R2(Test):<br>\n",
    "Dargestellt ist R2(train) in Klammern, dann R2(test) und das Verfahren<br><br>\n",
    "(88,7%) 86,2% Weight ~ Length1+ Length2 + Length3 + Height + Width (LR alle Features ohne Species)<br>\n",
    "(88,7%) 86,9% Weight ~ Length1 + Length3 + Height + Width (LR Forward Selection ohne Species)<br>\n",
    "(88,5%) 87,1% Weight ~ Length1 + Length3 + Height (LR Backward Selection ohne Species)<br>\n",
    "(93,6%) 89,7% Weight ~ Species + Length1 + Height + Width (LR mit Species)<br>\n",
    "(97,4%) 94,0% Weight ~ Species\\*Length1 + Species\\*Length3 + Species*Height + Width (LR it Species mit Interaktion)<br>\n",
    "(99,5%) 97,6% Random Forest Regressor<br>\n",
    "(97,8%) 98,3% Weight ~ np.square(Length1)+ Length2+np.square(Height)+np.square(Width) (LR ohne Species mit Featurestransforation)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Zusammenhänge zwischen Variablen: Scatterplot, Korrelationsmatrix, VIF</b>\n",
    "<li><b>Lineare Regression, Lasso, Ridge</b>\n",
    "<li><b>Forward Selection, Backward Eliminiation</b>\n",
    "<li><b>Kategorielle Variable in der Linearen Regression</b>\n",
    "<li><b>Transformation von Features</b>\n",
    "<li><b>Modellauswahl bei kleinen Datensätzen - verschiedene Trainings/Test-Splits, Kreuzvalidierung (leave one out CV)\n",
    "<li><b>Random Forest Regressor</b>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mögliche weitere Tätigkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<ul>\n",
    "<li>Validierung der Ergebnisse mittels Kreuzvalidierung (Sicherstellung dass Ergebnisse nicht zufällig sind)\n",
    "<li>Analyse der Datensätze mit den größten Prognosenfehlern<br>\n",
    "    Check nach fehlerhaften Daten, Anpassung Modell, zusätzliches Modell für Sonderfälle\n",
    "<li>Optimierung der Hyperparameter beim Random Forest Regressor\n",
    "    \n",
    "<li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellauswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performance auf den TRAININGSDATEN</b>\n",
    "<ul>\n",
    "<li><b>$R^2$ steigt mit zusätzlichen Features immer an (genauer: nimmt nie ab)</b>\n",
    "<li><b>$R^2$ ist immer $\\ge 0$</b>\n",
    "<li><b>Modellvergleich mit unterschiedlicher Anzahl Features: $adj. R^2$, AIC und BIC verwenden<br>(können zu verschiedenen Ergebnissen führen)</b>\n",
    "<li><b>$adj. R^2 = R^2$ bei einem Feature, sonst ist $adj. R^2 < R^2$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performance auf den TESTDATEN</b>\n",
    "<ul>\n",
    "<li><b>$R^2$ kann hier sogar negativ werden!</b>\n",
    "<li><b>Kein $adj. R^2$ verwenden, sondern $R^2$</b>\n",
    "<li><b>Bei kleinen Datensätzes - verschiendene TRainingssplits oder CV verwenden</b>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMgBuapJcVmt"
   },
   "source": [
    "# Beenden Aufzeichnen nicht vergessen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dd7196572b69c59cc0eccab309893e86548ddb8c2feba7c7f2bbdeb0303a6256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
