{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQr8z-ivMXBT"
   },
   "source": [
    "# WS24 DMML 25.11.2024: Pipeline (sklearn)<a class=\"jp-toc-ignore\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html<br>\n",
    "https://scikit-learn.org/1.5/glossary.html#term-predictor<br>\n",
    "https://scikit-learn.org/1.5/glossary.html#term-transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begriffsklärungen:<br>\n",
    "<b>Transformer: </b>Transformiert einen Input (normalerweise nur X) - bspw. standardscaler, PCA, ...<br>\n",
    "<b>Predictor: </b>Kann aus Inputdaten (X) Schätzungen von y erzeugen - bspw. classifier, regressor, outlier detector and clusterer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Eigenschaften einer Pipeline</b><br>\n",
    "\n",
    "<ul>\n",
    "<li>Mit einer Pipeline kann man mit Transformern die Inputdaten X transformieren (preprocessing) und (optional) danach einen Predictor einsetzen.\n",
    "<li>Eine Pipeline kann wie jeder andere Predictor verwendet werden.\n",
    "<li>Verhindert, dass Test- und Trainingsdaten vermischt werden (es wird nur mit Training trainiert).\n",
    "<li>Nutzen: die verschiedenen Schritte können zusammen kreuzvalidiert werden, zu jedem Schritt können verschiedene Parameter gesetzt werden.\n",
    "<li>Parametersetzung für verschiedene Schritte: Name des Schrittes gefolgt von \"__\".\n",
    "<li>Ein Transformer kann mit dem Parameter 'passthrough' übersprungen werden.\n",
    "</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline mit Parkinson-Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Code adapted from</b><br>\n",
    "https://www.kaggle.com/code/annatshngryan/pipeline-scaling-pca-logistic-regression<br>\n",
    "and<br>\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-download-auto-examples-compose-plot-digits-pipe-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, RepeatedKFold, train_test_split\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df       = pd.read_csv('pd_speech_features.csv',       skiprows = 1, usecols=lambda x: x != 'id')\n",
    "df_train = pd.read_csv('pd_speech_features-train.csv', skiprows = 1, usecols=lambda x: x != 'id')\n",
    "df_test  = pd.read_csv('pd_speech_features-test.csv',  skiprows = 1, usecols=lambda x: x != 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df       = df.rename(columns={'class': 'target'})\n",
    "df_train = df_train.rename(columns={'class': 'target'})\n",
    "df_test  = df_test.rename(columns={'class': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X       = df.drop('target', axis=1)\n",
    "X_train = df_train.drop('target', axis=1)\n",
    "X_test  = df_test.drop('target', axis=1)\n",
    "\n",
    "y       = df.target\n",
    "y_train = df_train.target\n",
    "y_test  = df_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (without Gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', PCA(n_components=.95)),\n",
    "         ('clf', LogisticRegression(max_iter=1000))]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check Performance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pipe.predict(X_test)\n",
    "print('Confusion Matrix(test):')\n",
    "print(confusion_matrix(y_test, y_test_pred))   # sklearn.metrics.confusion_matrix(y_true, y_pred,....\n",
    "print('Accuracy(test):', round(accuracy_score(y_test, y_test_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch + Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', PCA(n_components=.95)),\n",
    "         ('LogReg', LogisticRegression(max_iter=1000))]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Grid</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Parameter: name of step followed by '__'\n",
    "param_grid = {\n",
    "    'pca__n_components': [15, 30, 45, 60],\n",
    "    'LogReg__C'        : [0.001, 1, 10, 100]  }\n",
    "\n",
    "gridpoints = len(ParameterGrid(param_grid))\n",
    "\n",
    "print('Anzahl Parameterkombinationen: ', gridpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Art der Kreuzvalidierung (hier: RepeatedKFold) wird für Gridsearch definiert</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits  = 5\n",
    "n_repeats = 10\n",
    "splits    = n_splits * n_repeats   # Anzahl Durhläufe pro Parameterkombination\n",
    "\n",
    "cv = RepeatedKFold(n_splits= n_splits, n_repeats= n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit Gridsearch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs= -1, scoring= 'accuracy', cv= cv, refit= True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Anzahl Parameterkombis:', gridpoints)\n",
    "print('Anzahl Training-Validation-Splits:', splits)\n",
    "print('Anzahl Durchläufe:', gridpoints*splits)\n",
    "end = time.time()\n",
    "print('Dauer:', round(end - start), 'Sekunden')\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check Performance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = search.best_estimator_.predict(X_test)\n",
    "print('Confusion Matrix(test):')\n",
    "print(confusion_matrix(y_test, y_test_pred))   # sklearn.metrics.confusion_matrix(y_true, y_pred,....\n",
    "print('Accuracy(test):', round(accuracy_score(y_test, y_test_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Detailanalyse Gridsearch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameterkombinationen als Beschriftung der x-Achse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0,gridpoints):\n",
    "    components = str(search.cv_results_['params'][i]['pca__n_components'] )\n",
    "    c_values   = str(round(search.cv_results_['params'][i]['LogReg__C'],4))\n",
    "    labels.append( components + ' / ' + c_values )\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen einer Liste mit dem Namen der einzelnen Splits\n",
    "split_names = []\n",
    "for i in range(0,splits):\n",
    "    split_names.append('split' + str(i) + '_test_score')\n",
    "split_names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen einer Liste von Listen zur Sammlung der Accuracy pro Durchlauf\n",
    "# Äußere Liste geht über die Splits , die inner über die Gridpoints\n",
    "print('Splits (außen):',splits,', Gridpoints (innen):',gridpoints)\n",
    "acc = [  [0]*gridpoints ]  *(splits+3)\n",
    "print(acc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Die Liste acc wird mit den Accuracy pro Durchlauf befüllt\n",
    "# Zusätzlich werden median, mean und std für jeden Gridpoint berechnet\n",
    "i == 0\n",
    "for i in range(0,splits):\n",
    "    acc[i] = list(search.cv_results_[split_names[i]])\n",
    "acc[i+1] = np.median(acc[0:splits], axis = 0)                # Get median of array cols\n",
    "acc[i+2] = np.mean(acc[0:splits],   axis = 0)                # Get mean of array cols\n",
    "acc[i+3] = np.std(acc[0:splits],    axis = 0)                # Get std of array cols\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.3\n",
    "color = 'black'\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "title = 'Accuracy in Abhängigkeit der Hyperparameter-Kombinationen (splits:' + str(splits) + ')'\n",
    "plt.title(title)\n",
    "plt.xlabel('PCA-Components / C_values')\n",
    "plt.ylabel('Accuracy')\n",
    "for i in range(0,splits):\n",
    "    plt.plot(labels, acc[i],'o', color= 'lightgrey', alpha=alpha)\n",
    "plt.plot(labels,acc[i+1],'-o', color= 'red', alpha=1, label='median')\n",
    "plt.plot(labels,acc[i+2],'-o', color= 'blue', alpha=1, label='mean')\n",
    "plt.errorbar(labels, acc[i+2] , acc[i+3], linestyle='None', color='black', linewidth= 2, marker='', capsize=10, label='mean+-std')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0.7,1)\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch + Pipeline mit/ohne PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', PCA()),\n",
    "         ('LogReg', LogisticRegression(max_iter=1000))]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Grid</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {   'pca__n_components': [1, 15, 30, 45, 60, 75, 100],\n",
    "        'LogReg__C'        : [0.001, 1, 10, 100]  }\n",
    "    ,\n",
    "    {   'pca'              : ['passthrough'],       # skip PCA\n",
    "        'LogReg__C'        : [0.001, 1, 10, 100]  }        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_names  = []  # collects the names of the paramenters for single dictionaries\n",
    "paras_number = []  # collects the number of the paramenters for single dictionaries\n",
    "gridpoints   = []  # collects the numer of combinations for single dictionaries\n",
    "\n",
    "grid_dicts = len(param_grid)\n",
    "\n",
    "for i in range(0,grid_dicts):\n",
    "    paras_names.append(list(param_grid[i].keys()))\n",
    "    paras_number.append(len(list(param_grid[i].keys())))\n",
    "    gridpoints.append(len(ParameterGrid(param_grid[i])))  \n",
    "print('Namen der Parameter:', paras_names)\n",
    "print('Anzahl Parameter:', paras_number)\n",
    "print('Anzahl Gridpoints:', gridpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Kreuzvalidierung für Gridsearch wird definiert</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits  = 5\n",
    "n_repeats = 4\n",
    "splits    = n_splits * n_repeats   # Anzahl Splits pro Parameterkombination\n",
    "\n",
    "cv = RepeatedKFold(n_splits= n_splits, n_repeats= n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit Gridsearch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipe, param_grid, n_jobs = 2, scoring = 'accuracy', cv = cv)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs= -1, scoring= 'accuracy', cv= cv, refit= True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Anzahl Parameterkombis:', sum(gridpoints))\n",
    "print('Anzahl Training-Validation-Splits:', splits)\n",
    "print('Anzahl Durchläufe:', sum(gridpoints)*splits)\n",
    "end = time.time()\n",
    "print('Dauer:', round(end - start), 'Sekunden')\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameterkombinationen als Beschriftung der x-Achse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "row    = 0\n",
    "\n",
    "for i in range(0,grid_dicts):\n",
    "    for j in range(0,gridpoints[i]):\n",
    "        temp = ''\n",
    "        for para in paras_names[i]:\n",
    "            temp = temp + str(search.cv_results_['params'][row][para] ) + ' / '\n",
    "        temp = temp[:-3]\n",
    "        row += 1\n",
    "        labels.append(temp)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_names = []\n",
    "for i in range(0,splits):\n",
    "    split_names.append('split' + str(i) + '_test_score')\n",
    "split_names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen einer Liste von Listen zur Sammlung der Accuracy pro Durchlauf\n",
    "# Äußere Liste geht über die Splits , die inner über die Gridpoints\n",
    "print('Splits (außen):',splits,', Gridpoints (innen):',sum(gridpoints))\n",
    "acc = [  [0]*sum(gridpoints) ]  *(splits+3)\n",
    "print(acc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Liste acc wird mit den Accuracy pro Durchlauf befüllt\n",
    "# Zusätzlich werden median, mean und std für jeden Gridpoint berechnet\n",
    "i == 0\n",
    "for i in range(0,splits):\n",
    "    acc[i] = list(search.cv_results_[split_names[i]])\n",
    "acc[i+1] = np.median(acc[0:splits], axis = 0)                # Get median of array cols\n",
    "acc[i+2] = np.mean(acc[0:splits],   axis = 0)                # Get mean of array cols\n",
    "acc[i+3] = np.std(acc[0:splits],    axis = 0)                # Get std of array cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.3\n",
    "color = 'black'\n",
    "colormedian = 'red'\n",
    "colormean   = 'blue'\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "title = 'Accuracy in Abhängigkeit der Hyperparameter-Kombinationen (splits:' + str(splits) + ')'\n",
    "plt.title(title)\n",
    "plt.xlabel('PCA-Components / C_values')\n",
    "plt.ylabel('Accuracy')\n",
    "for i in range(0,splits):\n",
    "    plt.plot(labels, acc[i],'o', color= 'lightgrey', alpha=alpha)\n",
    "plt.plot(labels,acc[i+1],'-o', color= colormedian, alpha=1, label='median')\n",
    "plt.plot(labels,acc[i+2],'-o', color= colormean, alpha=1, label='mean')\n",
    "plt.errorbar(labels, acc[i+2] , acc[i+3], linestyle='None', color='black', linewidth= 2, marker='', capsize=6, label='mean+-std')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0.7,1)\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch + Pipeline verschiedene Klassifizierer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', PCA()),\n",
    "         ('clf', LogisticRegression(max_iter=1000))]    # LogisticRegression ist hier nur Platzhalter\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Definition Grid</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {   'pca__n_components': [1, 15, 30, 45, 60, 75, 100],\n",
    "        'clf'              : [LogisticRegression(max_iter=1000)] ,\n",
    "        'clf__C'           : [0.001, 1, 10, 100]  }     \n",
    "    ,\n",
    "    {   'pca__n_components': [1, 15, 30, 45, 60, 75, 100],\n",
    "        'clf'              : [SVC()]                }        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_names  = []  # collects the names of the paramenters for single dictionaries\n",
    "paras_number = []  # collects the number of the paramenters for single dictionaries\n",
    "gridpoints   = []  # collects the numer of combinations for single dictionaries\n",
    "\n",
    "grid_dicts = len(param_grid)\n",
    "\n",
    "for i in range(0,grid_dicts):\n",
    "    paras_names.append(list(param_grid[i].keys()))\n",
    "    paras_number.append(len(param_grid[i].keys()))\n",
    "    gridpoints.append(len(ParameterGrid(param_grid[i])))\n",
    "\n",
    "print('Namen der Parameter:', paras_names)\n",
    "print('Anzahl Parameter:', paras_number)\n",
    "print('Anzahl Gridpoints:', gridpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Kreuzvalidierung für GridSearch wird definiert</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits  = 5\n",
    "n_repeats = 4\n",
    "splits    = n_splits * n_repeats   # Anzahl Splits pro Parameterkombination\n",
    "\n",
    "cv = RepeatedKFold(n_splits= n_splits, n_repeats= n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit GridSearch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipe, param_grid, n_jobs=- 1, scoring = 'accuracy', cv= cv)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameterkombinationen als Beschriftung der x-Achse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "row    = 0\n",
    "\n",
    "for i in range(0,grid_dicts):\n",
    "    for j in range(0,gridpoints[i]):\n",
    "        temp = ''\n",
    "        for para in paras_names[i]:\n",
    "            temp = temp + str(search.cv_results_['params'][row][para] ) + ' / '\n",
    "        temp = temp[:-3]\n",
    "        row += 1\n",
    "        labels.append(temp)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_names = []\n",
    "for i in range(0,splits):\n",
    "    split_names.append('split' + str(i) + '_test_score')\n",
    "split_names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen einer Liste von Listen zur Sammlung der Accuracy pro Durchlauf\n",
    "# Äußere Liste geht über die Splits , die inner über die Gridpoints\n",
    "print('Splits (außen):',splits,', Gridpoints (innen):',sum(gridpoints))\n",
    "acc = [  [0]*sum(gridpoints) ]  *(splits+3)\n",
    "print(acc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Liste acc wird mit den Accuracy pro Durchlauf befüllt\n",
    "# Zusätzlich werden median, mean und std für jeden Gridpoint berechnet\n",
    "i == 0\n",
    "for i in range(0,splits):\n",
    "    acc[i] = list(search.cv_results_[split_names[i]])\n",
    "acc[i+1] = np.median(acc[0:splits], axis = 0)                # Get median of array cols\n",
    "acc[i+2] = np.mean(acc[0:splits],   axis = 0)                # Get mean of array cols\n",
    "acc[i+3] = np.std(acc[0:splits],    axis = 0)                # Get std of array cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.3\n",
    "color = 'black'\n",
    "colormedian = 'red'\n",
    "colormean   = 'blue'\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "title = 'Accuracy in Abhängigkeit der Hyperparameter-Kombinationen (splits:' + str(splits) + ')'\n",
    "plt.title(title)\n",
    "plt.xlabel('PCA-Components / C_values')\n",
    "plt.ylabel('Accuracy')\n",
    "for i in range(0,splits):\n",
    "    plt.plot(labels, acc[i],'o', color= 'lightgrey', alpha=alpha)\n",
    "plt.plot(labels,acc[i+1],'-o', color= colormedian, alpha=1, label='median')\n",
    "plt.plot(labels,acc[i+2],'-o', color= colormean, alpha=1, label='mean')\n",
    "plt.errorbar(labels, acc[i+2] , acc[i+3], linestyle='None', color='black', linewidth= 2, marker='', capsize=6, label='mean+-std')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0.7,1)\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMgBuapJcVmt"
   },
   "source": [
    "# Beenden Aufzeichnen nicht vergessen"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.583px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "dd7196572b69c59cc0eccab309893e86548ddb8c2feba7c7f2bbdeb0303a6256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
